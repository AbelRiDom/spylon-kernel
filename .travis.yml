sudo: false
dist: trusty
language: python
python:
  - "2.7"
  - "3.5"
before_install:
  # Install a version of Spark to test this against
  - wget http://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz
  - tar xf spark-2.0.2-bin-hadoop2.7.tgz -C $HOME/.cache/spark
env:
  - SPARK_HOME=$HOME/.cache/spark/spark-2.0.2-bin-hadoop2.7 SPARK_SUBMIT_OPTS="-Dscala.usejavacp=true" PYTHONUNBUFFERED=1
install:
  - pip install -r requirements.txt
  - pip install .
  - pip install codecov coverage jupyter_kernel_test
  - python -m spylon_kernel install --user
script:
  # Delete the jupyter kernel test when testing with py27, since it relies on features from unittest only present
  # in python 3
  - if [[ "$TRAVIS_PYTHON_VERSION" == "2.7" ]]; then
        rm test_spylon_kernel_jkt.py;
    fi
  - coverage run run_tests.py -vrsx --capture=sys --color=yes
  - coverage report -m
  
# Cache these at the end of the build
cache:     
  directories:
    - $HOME/.cache/pip
    - $HOME/.cache/spark

after_success:
    - codecov
